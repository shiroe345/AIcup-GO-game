{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb173248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, Flatten, Dense, Softmax\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62384345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.10.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76ada379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "# if gpus:\n",
    "#     # Restrict TensorFlow to only use the first GPU\n",
    "#     try:\n",
    "#         for gpu in gpus:\n",
    "#             tf.config.experimental.set_memory_growth(gpu, False)\n",
    "#             tf.config.experimental.set_virtual_device_configuration(\n",
    "#                 gpu,\n",
    "#                 [\n",
    "#                     tf.config.experimental.VirtualDeviceConfiguration(\n",
    "#                         memory_limit=4096  # set your limit\n",
    "#                     )\n",
    "#                 ],\n",
    "#             )\n",
    "#         tf.config.experimental.set_visible_devices(gpus[0], \"GPU\")\n",
    "#         logical_gpus = tf.config.experimental.list_logical_devices(\"GPU\")\n",
    "#         print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "#     except RuntimeError as e:\n",
    "#         # Visible devices must be set before GPUs have been initialized\n",
    "#         print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0c3979f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "\n",
    "if len(physical_devices) == 0:\n",
    "    print(\"No GPU devices found. Using CPU.\")\n",
    "else:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd95ed0c",
   "metadata": {},
   "source": [
    "# Data Pre-Processing\n",
    "\n",
    "Open **kyu_train.csv** file and split the games into a list.\n",
    "Every row of csv: `DL0000000001,B,B[pd],W[dp],B[pp],W[dc],B[de],...`. \n",
    "\n",
    "Columns are:\n",
    "\n",
    "    1. DL0000000001: Game ID\n",
    "    2. B: Player's color\n",
    "    3-... : Moves\n",
    "    \n",
    "We cropped only the moves to game list as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f8872fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118500\n"
     ]
    }
   ],
   "source": [
    "df = open('./Training Dataset/kyu_train.csv').read().splitlines()\n",
    "games = [i.split(',',2)[-1] for i in df]\n",
    "random.shuffle(games)\n",
    "print(len(games))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58532b01",
   "metadata": {},
   "source": [
    "Create a dictionary to convert the coordinates from characters to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "496585f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0,\n",
       " 'b': 1,\n",
       " 'c': 2,\n",
       " 'd': 3,\n",
       " 'e': 4,\n",
       " 'f': 5,\n",
       " 'g': 6,\n",
       " 'h': 7,\n",
       " 'i': 8,\n",
       " 'j': 9,\n",
       " 'k': 10,\n",
       " 'l': 11,\n",
       " 'm': 12,\n",
       " 'n': 13,\n",
       " 'o': 14,\n",
       " 'p': 15,\n",
       " 'q': 16,\n",
       " 'r': 17,\n",
       " 's': 18}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = 'abcdefghijklmnopqrs'\n",
    "coordinates = {k:v for v,k in enumerate(chars)}\n",
    "chartonumbers = {k:v for k,v in enumerate(chars)}\n",
    "coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92277370",
   "metadata": {},
   "source": [
    "We decided to build a DCNN model in this tutorial. We create data samples by using every move in every game, meaning that the target is to predict the next move by feeding the previous state of the table in every game for every move. Therefore, we can collect much more data samples from games.\n",
    "\n",
    "For the simplicity, we used 4 dimensional feature map to represent the data as below:\n",
    " 1. Positions of black stones: mark them as 1 and the rest of the table as 0\n",
    " 2. Positions of white stones: mark them as 1 and the rest of the table as 0\n",
    " 3. Empty areas of the table: mark the empty areas as 1 and occupied areas as 0\n",
    " 4. The last move in the table: mark the position of the last move as 1 and the rest as 0\n",
    " \n",
    "Target value is a number between 0-361(19\\*19). Later this will be one-hot encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0adb423c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input(moves):\n",
    "    x = np.zeros((19,19,4))\n",
    "    for move in moves:\n",
    "        color = move[0]\n",
    "        column = coordinates[move[2]]\n",
    "        row = coordinates[move[3]]\n",
    "        if color == 'B':\n",
    "            x[row,column,0] = 1\n",
    "            x[row,column,2] = 1\n",
    "        if color == 'W':\n",
    "            x[row,column,1] = 1\n",
    "            x[row,column,2] = 1\n",
    "    if moves:\n",
    "        last_move_column = coordinates[moves[-1][2]]\n",
    "        last_move_row = coordinates[moves[-1][3]]\n",
    "        x[row,column,3] = 1\n",
    "    x[:,:,2] = np.where(x[:,:,2] == 0, 1, 0)\n",
    "    return x\n",
    "\n",
    "def prepare_label(move):\n",
    "    column = coordinates[move[2]]\n",
    "    row = coordinates[move[3]]\n",
    "    return column*19+row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "758808ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check how many samples can be obtained\n",
    "# n_games = 0\n",
    "# n_moves = 0\n",
    "# for game in games[:500]:\n",
    "#     n_games += 1\n",
    "#     moves_list = game.split(',')\n",
    "#     for move in moves_list:\n",
    "#         n_moves += 1\n",
    "# print(f\"Total Games: {n_games}, Total Moves: {n_moves}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46403360",
   "metadata": {},
   "source": [
    "The code below is run for baseline model only by using only the first 500 games from the dataset. You might need to create a data generator to use complete dataset. Otherwise your RAM might not enough to store all (If you run the code on free version of Google Colab, it will crash above 500 game samples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9bb0ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = []\n",
    "# y = []\n",
    "# for game in games[:500]:\n",
    "#     moves_list = game.split(',')\n",
    "#     for count, move in enumerate(moves_list):\n",
    "#         x.append(prepare_input(moves_list[:count]))\n",
    "#         y.append(prepare_label(moves_list[count]))\n",
    "# x = np.array(x)\n",
    "# y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b2392a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73521b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5510a7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_one_hot = tf.one_hot(y, depth=19*19)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b048ff",
   "metadata": {},
   "source": [
    "Dataset splitting: 90% Training, 10% validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f594acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train, x_val, y_train, y_val = train_test_split(x, y_one_hot.numpy(), test_size=0.10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e34f83f",
   "metadata": {},
   "source": [
    "### PyTorch version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e717c3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import torch.nn.functional as F\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# # Assuming you have a PyTorch version that supports torch.device\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# df = open('./Training Dataset/kyu_train.csv').read().splitlines()\n",
    "# games = [i.split(',', 2)[-1] for i in df]\n",
    "# print(len(games))\n",
    "\n",
    "# chars = 'abcdefghijklmnopqrs'\n",
    "# coordinates = {k: v for v, k in enumerate(chars)}\n",
    "# chartonumbers = {k: v for k, v in enumerate(chars)}\n",
    "\n",
    "# def prepare_input(moves):\n",
    "#     x = np.zeros((19,19,4))\n",
    "#     for move in moves:\n",
    "#         color = move[0]\n",
    "#         column = coordinates[move[2]]\n",
    "#         row = coordinates[move[3]]\n",
    "#         if color == 'B':\n",
    "#             x[row,column,0] = 1\n",
    "#             x[row,column,2] = 1\n",
    "#         if color == 'W':\n",
    "#             x[row,column,1] = 1\n",
    "#             x[row,column,2] = 1\n",
    "#     if moves:\n",
    "#         last_move_column = coordinates[moves[-1][2]]\n",
    "#         last_move_row = coordinates[moves[-1][3]]\n",
    "#         x[row,column,3] = 1\n",
    "#     x[:,:,2] = np.where(x[:,:,2] == 0, 1, 0)\n",
    "#     return x\n",
    "\n",
    "# def prepare_label(move):\n",
    "#     column = coordinates[move[2]]\n",
    "#     row = coordinates[move[3]]\n",
    "#     return column*19+row\n",
    "\n",
    "# def accuracy(predictions, targets):\n",
    "#     with torch.no_grad():\n",
    "#         _, predicted = torch.max(predictions, 1)\n",
    "#         correct = (predicted == targets).sum().item()\n",
    "#         total = targets.size(0)\n",
    "#         acc = correct / total\n",
    "#     return acc\n",
    "\n",
    "# class SimpleModel(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(SimpleModel, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(4, 32, kernel_size=7, padding='same')\n",
    "#         self.conv2 = nn.Conv2d(32, 32, kernel_size=7, padding='same')\n",
    "#         self.conv3 = nn.Conv2d(32, 32, kernel_size=5, padding='same')\n",
    "#         self.conv4 = nn.Conv2d(32, 32, kernel_size=5, padding='same')\n",
    "#         self.conv5 = nn.Conv2d(32, 32, kernel_size=3, padding='same')\n",
    "#         self.conv6 = nn.Conv2d(32, 1, kernel_size=3, padding='same')\n",
    "#         self.flatten = nn.Flatten()\n",
    "#         self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(self.conv1(x))\n",
    "#         x = F.relu(self.conv2(x))\n",
    "#         x = F.relu(self.conv3(x))\n",
    "#         x = F.relu(self.conv4(x))\n",
    "#         x = F.relu(self.conv5(x))\n",
    "#         x = F.relu(self.conv6(x))\n",
    "#         x = self.flatten(x)\n",
    "#         return x\n",
    "\n",
    "# def create_model():\n",
    "#     model = SimpleModel()\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "#     criterion = nn.CrossEntropyLoss()\n",
    "#     return model, optimizer, criterion\n",
    "\n",
    "# model, optimizer, criterion = create_model()\n",
    "# print(model)\n",
    "# model.to(device)\n",
    "\n",
    "# batch_size = 128\n",
    "# batch = 1\n",
    "\n",
    "# for batch_start in range(0, len(games), batch_size):\n",
    "#     print(\"epoch\", batch)\n",
    "#     batch_end = batch_start + batch_size\n",
    "#     batch_games = games[batch_start:batch_end]\n",
    "#     x = []\n",
    "#     y = []\n",
    "#     for game in batch_games:\n",
    "#         moves_list = game.split(',')\n",
    "#         for count, move in enumerate(moves_list):\n",
    "#             x.append(prepare_input(moves_list[:count]))\n",
    "#             y.append(prepare_label(moves_list[count]))\n",
    "\n",
    "#     x = torch.tensor(np.array(x), dtype=torch.float32).permute(0, 3, 1, 2).to(device)\n",
    "#     y = torch.tensor(np.array(y), dtype=torch.long).to(device)\n",
    "\n",
    "#     x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.10)\n",
    "\n",
    "#     for epoch in range(1):\n",
    "#         outputs = model(x_train)\n",
    "#         loss = criterion(outputs, y_train.view(-1))  # Flatten y_train\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#     print(\"val_acc:\", accuracy(model(x_val), y_val))\n",
    "#     print(\"val_loss:\", loss.item())\n",
    "\n",
    "#     if batch % 30 == 0:\n",
    "#         torch.save(model.state_dict(), f\"./models/kyu_{batch}_{accuracy(model(x_val), y_val):.5f}_{loss.item():.5f}.pth\")\n",
    "\n",
    "#     batch += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9c5de9",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "### Simple DCNN Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fa9006a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd67e439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 15348), started 3:17:07 ago. (Use '!kill 15348' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-3a51f5043a9d2585\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-3a51f5043a9d2585\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=path/to/logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6616a700",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_num = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "208834da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    inputs = Input(shape=(19, 19, 4))\n",
    "\n",
    "    outputs = Conv2D(kernel_size=7, filters=32, padding='same', activation='relu')(inputs)\n",
    "    outputs = Conv2D(kernel_size=7, filters=32, padding='same', activation='relu')(outputs)\n",
    "    outputs = Conv2D(kernel_size=5, filters=32, padding='same', activation='relu')(outputs)\n",
    "    outputs = Conv2D(kernel_size=5, filters=32, padding='same', activation='relu')(outputs)\n",
    "    outputs = Conv2D(kernel_size=3, filters=32, padding='same', activation='relu')(outputs)\n",
    "    outputs = Conv2D(kernel_size=3, filters=1, padding='same', activation='relu')(outputs)\n",
    "    outputs = Flatten()(outputs)\n",
    "    outputs = Softmax()(outputs)\n",
    "    model = Model(inputs, outputs)\n",
    "    \n",
    "    opt = Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1107ec82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model1():\n",
    "    inputs = Input(shape=(19, 19, 4))\n",
    "    \n",
    "    x = Conv2D(kernel_size=7, filters=64, padding='same', activation='relu')(inputs)\n",
    "    x = BatchNormalization()(x)  # Add BatchNormalization\n",
    "    x = Conv2D(kernel_size=7, filters=64, padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(kernel_size=5, filters=64, padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(kernel_size=5, filters=64, padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(kernel_size=3, filters=64, padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(kernel_size=3, filters=1, padding='same', activation='relu')(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "\n",
    "    policy_head = Dense(361, activation='softmax', name='policy')(x)\n",
    "    value_head = Dense(1, activation='tanh', name='value')(x)\n",
    "\n",
    "    model = Model(inputs, [policy_head, value_head])\n",
    "\n",
    "    opt = Adam(learning_rate=0.001)\n",
    "\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss={'policy': 'categorical_crossentropy', 'value': 'mean_squared_error'},\n",
    "                  metrics={'policy': 'accuracy', 'value': 'mae'})\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5020cc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model2():\n",
    "    inputs = Input(shape=(19, 19, 4))\n",
    "\n",
    "    outputs = Conv2D(kernel_size=7, filters=64, padding='same', activation='relu')(inputs)\n",
    "    outputs = BatchNormalization()(outputs)\n",
    "    outputs = Conv2D(kernel_size=7, filters=64, padding='same', activation='relu')(outputs)\n",
    "    outputs = BatchNormalization()(outputs)\n",
    "    outputs = Conv2D(kernel_size=5, filters=64, padding='same', activation='relu')(outputs)\n",
    "    outputs = BatchNormalization()(outputs)\n",
    "    outputs = Conv2D(kernel_size=5, filters=64, padding='same', activation='relu')(outputs)\n",
    "    outputs = BatchNormalization()(outputs)\n",
    "    outputs = Conv2D(kernel_size=3, filters=64, padding='same', activation='relu')(outputs)\n",
    "    outputs = BatchNormalization()(outputs)\n",
    "    outputs = Conv2D(kernel_size=3, filters=1, padding='same', activation='relu')(outputs)\n",
    "    outputs = Flatten()(outputs)\n",
    "    outputs = Dense(256, activation='relu')(outputs)\n",
    "    outputs = Dropout(0.5)(outputs)\n",
    "    outputs = Dense(361, activation='softmax')(outputs)  # Adjust the number of units based on your output space\n",
    "    model = Model(inputs, outputs)\n",
    "    \n",
    "    opt = Adam(learning_rate=0.001)  # Adjust the learning rate\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss='categorical_crossentropy',  # Change to sparse_categorical_crossentropy\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a66e90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 19, 19, 4)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 19, 19, 64)        12608     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 19, 19, 64)       256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 19, 19, 64)        200768    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 19, 19, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 19, 19, 64)        102464    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 19, 19, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 19, 19, 64)        102464    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 19, 19, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 19, 19, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 19, 19, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 19, 19, 1)         577       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 361)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               92672     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 361)               92777     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 642,538\n",
      "Trainable params: 641,898\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model2()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7ec53e",
   "metadata": {},
   "source": [
    "## data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "993f365a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.backend import set_session\n",
    "from keras.backend import clear_session\n",
    "from keras.backend import get_session\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import gc\n",
    "import math\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "773128b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reset keras function from: https://github.com/keras-team/keras/issues/12625\n",
    "def reset_keras():\n",
    "    sess = get_session()\n",
    "    clear_session()\n",
    "    sess.close()\n",
    "    sess = get_session()\n",
    "\n",
    "    # try:\n",
    "    #     del classifier # this is from global space - change this as you need\n",
    "    # except:\n",
    "    #     pass\n",
    "    gc.collect()\n",
    "    # print(\"Garbage Collected: \" + gc.collect()) # if it's done something you should see a number being outputted\n",
    "\n",
    "    # use the same config as you used to create the session\n",
    "    gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=1, visible_device_list=\"0\")\n",
    "    config = tf.compat.v1.ConfigProto(gpu_options=gpu_options)\n",
    "    set_session(tf.compat.v1.Session(config=config))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f467a977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming prepare_input and prepare_label functions are defined elsewhere\n",
    "def data_generator(games, batch_size):\n",
    "    for batch_start in range(0, len(games), batch_size):\n",
    "        batch_end = batch_start + batch_size\n",
    "        batch_games = games[batch_start:batch_end]\n",
    "        x = []\n",
    "        y = []\n",
    "        for game in batch_games:\n",
    "            moves_list = game.split(',')\n",
    "            for count, move in enumerate(moves_list):\n",
    "                x.append(prepare_input(moves_list[:count]))\n",
    "                y.append(prepare_label(moves_list[count]))\n",
    "\n",
    "        x = np.array(x)\n",
    "        y = np.array(y)\n",
    "\n",
    "        y_one_hot = tf.one_hot(y, depth=19*19)\n",
    "\n",
    "        x_train, x_val, y_train, y_val = train_test_split(x, y_one_hot.numpy(), test_size=0.10)\n",
    "\n",
    "        yield (x_train, y_train, x_val, y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c4727de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "1/232\n",
      "208/208 [==============================] - 17s 78ms/step - loss: 5.8389 - accuracy: 0.0048 - val_loss: 5.8684 - val_accuracy: 0.0025\n",
      "2/232\n",
      "208/208 [==============================] - 17s 80ms/step - loss: 5.0051 - accuracy: 0.0311 - val_loss: 4.5373 - val_accuracy: 0.0497\n",
      "3/232\n",
      "207/207 [==============================] - 17s 80ms/step - loss: 4.3549 - accuracy: 0.0587 - val_loss: 4.4454 - val_accuracy: 0.0680\n",
      "4/232\n",
      "204/204 [==============================] - 16s 80ms/step - loss: 4.1244 - accuracy: 0.0874 - val_loss: 3.9777 - val_accuracy: 0.0984\n",
      "5/232\n",
      "212/212 [==============================] - 17s 80ms/step - loss: 3.9818 - accuracy: 0.1283 - val_loss: 3.9228 - val_accuracy: 0.1659\n",
      "6/232\n",
      "208/208 [==============================] - 17s 80ms/step - loss: 3.7630 - accuracy: 0.2204 - val_loss: 3.5124 - val_accuracy: 0.3032\n",
      "7/232\n",
      "205/205 [==============================] - 16s 80ms/step - loss: 3.4893 - accuracy: 0.3059 - val_loss: 3.2379 - val_accuracy: 0.3518\n",
      "8/232\n",
      "206/206 [==============================] - 17s 79ms/step - loss: 3.3392 - accuracy: 0.3339 - val_loss: 3.1006 - val_accuracy: 0.3613\n",
      "9/232\n",
      "207/207 [==============================] - 17s 79ms/step - loss: 3.2386 - accuracy: 0.3515 - val_loss: 3.0638 - val_accuracy: 0.3695\n",
      "10/232\n",
      "211/211 [==============================] - 16s 76ms/step - loss: 3.2011 - accuracy: 0.3588 - val_loss: 2.9996 - val_accuracy: 0.3801\n",
      "11/232\n",
      "206/206 [==============================] - 16s 76ms/step - loss: 3.1197 - accuracy: 0.3697 - val_loss: 2.9233 - val_accuracy: 0.3896\n",
      "12/232\n",
      "208/208 [==============================] - 16s 75ms/step - loss: 3.0761 - accuracy: 0.3793 - val_loss: 2.8861 - val_accuracy: 0.4051\n",
      "13/232\n",
      "204/204 [==============================] - 16s 76ms/step - loss: 3.0273 - accuracy: 0.3801 - val_loss: 2.8439 - val_accuracy: 0.3952\n",
      "14/232\n",
      "205/205 [==============================] - 16s 76ms/step - loss: 2.9901 - accuracy: 0.3865 - val_loss: 2.8029 - val_accuracy: 0.4242\n",
      "15/232\n",
      "205/205 [==============================] - 16s 75ms/step - loss: 2.9714 - accuracy: 0.3900 - val_loss: 2.7511 - val_accuracy: 0.4064\n",
      "16/232\n",
      "210/210 [==============================] - 16s 76ms/step - loss: 2.9851 - accuracy: 0.3906 - val_loss: 2.7794 - val_accuracy: 0.4104\n",
      "17/232\n",
      "205/205 [==============================] - 16s 75ms/step - loss: 2.9230 - accuracy: 0.3968 - val_loss: 2.7196 - val_accuracy: 0.4162\n",
      "18/232\n",
      "207/207 [==============================] - 16s 75ms/step - loss: 2.8998 - accuracy: 0.4001 - val_loss: 2.6753 - val_accuracy: 0.4204\n",
      "19/232\n",
      "208/208 [==============================] - 16s 78ms/step - loss: 2.9038 - accuracy: 0.4010 - val_loss: 2.6810 - val_accuracy: 0.4208\n",
      "20/232\n",
      "207/207 [==============================] - 16s 76ms/step - loss: 2.8854 - accuracy: 0.4037 - val_loss: 2.6732 - val_accuracy: 0.4254\n",
      "21/232\n",
      "207/207 [==============================] - 16s 75ms/step - loss: 2.8738 - accuracy: 0.4063 - val_loss: 2.6800 - val_accuracy: 0.4286\n",
      "22/232\n",
      "203/203 [==============================] - 16s 76ms/step - loss: 2.8440 - accuracy: 0.4095 - val_loss: 2.6633 - val_accuracy: 0.4188\n",
      "23/232\n",
      "205/205 [==============================] - 16s 76ms/step - loss: 2.8236 - accuracy: 0.4122 - val_loss: 2.6130 - val_accuracy: 0.4332\n",
      "24/232\n",
      "206/206 [==============================] - 16s 76ms/step - loss: 2.8050 - accuracy: 0.4166 - val_loss: 2.5807 - val_accuracy: 0.4382\n",
      "25/232\n",
      "207/207 [==============================] - 16s 76ms/step - loss: 2.8203 - accuracy: 0.4162 - val_loss: 2.6033 - val_accuracy: 0.4367\n",
      "26/232\n",
      "209/209 [==============================] - 16s 75ms/step - loss: 2.7981 - accuracy: 0.4163 - val_loss: 2.5546 - val_accuracy: 0.4375\n",
      "27/232\n",
      "207/207 [==============================] - 16s 75ms/step - loss: 2.7896 - accuracy: 0.4173 - val_loss: 2.5716 - val_accuracy: 0.4394\n",
      "28/232\n",
      "207/207 [==============================] - 16s 75ms/step - loss: 2.7686 - accuracy: 0.4230 - val_loss: 2.5621 - val_accuracy: 0.4360\n",
      "29/232\n",
      "207/207 [==============================] - 16s 76ms/step - loss: 2.7685 - accuracy: 0.4197 - val_loss: 2.5659 - val_accuracy: 0.4354\n",
      "30/232\n",
      "207/207 [==============================] - 16s 76ms/step - loss: 2.7630 - accuracy: 0.4211 - val_loss: 2.5669 - val_accuracy: 0.4347\n",
      "31/232\n",
      "203/203 [==============================] - 15s 76ms/step - loss: 2.7471 - accuracy: 0.4252 - val_loss: 2.5467 - val_accuracy: 0.4474\n",
      "32/232\n",
      "207/207 [==============================] - 16s 75ms/step - loss: 2.7086 - accuracy: 0.4303 - val_loss: 2.5298 - val_accuracy: 0.4446\n",
      "33/232\n",
      "209/209 [==============================] - 17s 79ms/step - loss: 2.7407 - accuracy: 0.4237 - val_loss: 2.5395 - val_accuracy: 0.4387\n",
      "34/232\n",
      "209/209 [==============================] - 17s 80ms/step - loss: 2.7266 - accuracy: 0.4275 - val_loss: 2.5482 - val_accuracy: 0.4400\n",
      "35/232\n",
      "208/208 [==============================] - 17s 79ms/step - loss: 2.7515 - accuracy: 0.4209 - val_loss: 2.6195 - val_accuracy: 0.4243\n",
      "36/232\n",
      "210/210 [==============================] - 17s 80ms/step - loss: 2.7088 - accuracy: 0.4289 - val_loss: 2.5496 - val_accuracy: 0.4419\n",
      "37/232\n",
      "206/206 [==============================] - 16s 79ms/step - loss: 2.7249 - accuracy: 0.4267 - val_loss: 2.5410 - val_accuracy: 0.4362\n",
      "38/232\n",
      "209/209 [==============================] - 17s 79ms/step - loss: 2.7012 - accuracy: 0.4306 - val_loss: 2.4710 - val_accuracy: 0.4509\n",
      "39/232\n",
      "202/202 [==============================] - 16s 80ms/step - loss: 2.6805 - accuracy: 0.4337 - val_loss: 2.4906 - val_accuracy: 0.4517\n",
      "40/232\n",
      "209/209 [==============================] - 17s 80ms/step - loss: 2.7169 - accuracy: 0.4241 - val_loss: 2.4610 - val_accuracy: 0.4491\n",
      "41/232\n",
      "205/205 [==============================] - 17s 80ms/step - loss: 2.6707 - accuracy: 0.4333 - val_loss: 2.4572 - val_accuracy: 0.4569\n",
      "42/232\n",
      "207/207 [==============================] - 17s 79ms/step - loss: 2.6646 - accuracy: 0.4352 - val_loss: 2.4716 - val_accuracy: 0.4498\n",
      "43/232\n",
      "208/208 [==============================] - 17s 80ms/step - loss: 2.6901 - accuracy: 0.4322 - val_loss: 2.4839 - val_accuracy: 0.4436\n",
      "44/232\n",
      "205/205 [==============================] - 16s 76ms/step - loss: 2.6668 - accuracy: 0.4353 - val_loss: 2.4495 - val_accuracy: 0.4504\n",
      "45/232\n",
      "206/206 [==============================] - 16s 78ms/step - loss: 2.6856 - accuracy: 0.4305 - val_loss: 2.4775 - val_accuracy: 0.4455\n",
      "46/232\n",
      "208/208 [==============================] - 16s 78ms/step - loss: 2.6877 - accuracy: 0.4292 - val_loss: 2.5098 - val_accuracy: 0.4444\n",
      "47/232\n",
      "205/205 [==============================] - 16s 79ms/step - loss: 2.6652 - accuracy: 0.4351 - val_loss: 2.4913 - val_accuracy: 0.4563\n",
      "48/232\n",
      "209/209 [==============================] - 16s 75ms/step - loss: 2.6457 - accuracy: 0.4345 - val_loss: 2.4146 - val_accuracy: 0.4504\n",
      "49/232\n",
      "207/207 [==============================] - 17s 80ms/step - loss: 2.6381 - accuracy: 0.4379 - val_loss: 2.4290 - val_accuracy: 0.4587\n",
      "50/232\n",
      "205/205 [==============================] - 16s 77ms/step - loss: 2.6470 - accuracy: 0.4340 - val_loss: 2.4563 - val_accuracy: 0.4444\n",
      "51/232\n",
      "207/207 [==============================] - 16s 76ms/step - loss: 2.6387 - accuracy: 0.4393 - val_loss: 2.4724 - val_accuracy: 0.4580\n",
      "52/232\n",
      "209/209 [==============================] - 16s 76ms/step - loss: 2.6508 - accuracy: 0.4365 - val_loss: 2.4256 - val_accuracy: 0.4560\n",
      "53/232\n",
      "206/206 [==============================] - 16s 76ms/step - loss: 2.6315 - accuracy: 0.4359 - val_loss: 2.4443 - val_accuracy: 0.4468\n",
      "54/232\n",
      "207/207 [==============================] - 16s 76ms/step - loss: 2.6426 - accuracy: 0.4359 - val_loss: 2.4648 - val_accuracy: 0.4461\n",
      "55/232\n",
      "206/206 [==============================] - 16s 76ms/step - loss: 2.6023 - accuracy: 0.4424 - val_loss: 2.4415 - val_accuracy: 0.4489\n",
      "56/232\n",
      "211/211 [==============================] - 16s 76ms/step - loss: 2.6241 - accuracy: 0.4394 - val_loss: 2.4886 - val_accuracy: 0.4544\n",
      "57/232\n",
      "205/205 [==============================] - 16s 76ms/step - loss: 2.6154 - accuracy: 0.4426 - val_loss: 2.4008 - val_accuracy: 0.4601\n",
      "58/232\n",
      "208/208 [==============================] - 16s 76ms/step - loss: 2.6401 - accuracy: 0.4380 - val_loss: 2.4119 - val_accuracy: 0.4617\n",
      "59/232\n",
      "205/205 [==============================] - 16s 76ms/step - loss: 2.6153 - accuracy: 0.4412 - val_loss: 2.4373 - val_accuracy: 0.4580\n",
      "60/232\n",
      "211/211 [==============================] - 16s 76ms/step - loss: 2.6092 - accuracy: 0.4421 - val_loss: 2.4963 - val_accuracy: 0.4427\n",
      "61/232\n",
      "206/206 [==============================] - 16s 76ms/step - loss: 2.5966 - accuracy: 0.4444 - val_loss: 2.4214 - val_accuracy: 0.4570\n",
      "62/232\n",
      "207/207 [==============================] - 16s 76ms/step - loss: 2.6150 - accuracy: 0.4417 - val_loss: 2.4025 - val_accuracy: 0.4645\n",
      "63/232\n",
      "204/204 [==============================] - 16s 76ms/step - loss: 2.5865 - accuracy: 0.4461 - val_loss: 2.4665 - val_accuracy: 0.4525\n",
      "64/232\n",
      "203/203 [==============================] - 16s 76ms/step - loss: 2.5629 - accuracy: 0.4491 - val_loss: 2.3940 - val_accuracy: 0.4605\n",
      "65/232\n",
      "205/205 [==============================] - 16s 76ms/step - loss: 2.6174 - accuracy: 0.4429 - val_loss: 2.3710 - val_accuracy: 0.4631\n",
      "66/232\n",
      "213/213 [==============================] - 16s 76ms/step - loss: 2.6280 - accuracy: 0.4358 - val_loss: 2.4170 - val_accuracy: 0.4577\n",
      "67/232\n",
      "204/204 [==============================] - 16s 76ms/step - loss: 2.5729 - accuracy: 0.4456 - val_loss: 2.3634 - val_accuracy: 0.4632\n",
      "68/232\n",
      "207/207 [==============================] - 16s 76ms/step - loss: 2.5751 - accuracy: 0.4463 - val_loss: 2.3841 - val_accuracy: 0.4634\n",
      "69/232\n",
      "208/208 [==============================] - 16s 76ms/step - loss: 2.6129 - accuracy: 0.4399 - val_loss: 2.4733 - val_accuracy: 0.4526\n",
      "70/232\n",
      "206/206 [==============================] - 16s 76ms/step - loss: 2.5617 - accuracy: 0.4497 - val_loss: 2.3977 - val_accuracy: 0.4527\n",
      "71/232\n",
      "207/207 [==============================] - 16s 76ms/step - loss: 2.5776 - accuracy: 0.4437 - val_loss: 2.4578 - val_accuracy: 0.4472\n",
      "72/232\n",
      "207/207 [==============================] - 16s 76ms/step - loss: 2.5957 - accuracy: 0.4417 - val_loss: 2.3798 - val_accuracy: 0.4582\n",
      "73/232\n",
      "204/204 [==============================] - 16s 76ms/step - loss: 2.5757 - accuracy: 0.4513 - val_loss: 2.3536 - val_accuracy: 0.4692\n",
      "74/232\n",
      "206/206 [==============================] - 16s 76ms/step - loss: 2.5522 - accuracy: 0.4486 - val_loss: 2.3622 - val_accuracy: 0.4636\n",
      "75/232\n",
      "208/208 [==============================] - 16s 76ms/step - loss: 2.5598 - accuracy: 0.4489 - val_loss: 2.4019 - val_accuracy: 0.4560\n",
      "76/232\n",
      "208/208 [==============================] - 16s 76ms/step - loss: 2.5646 - accuracy: 0.4450 - val_loss: 2.3839 - val_accuracy: 0.4656\n",
      "77/232\n",
      "207/207 [==============================] - 16s 76ms/step - loss: 2.5637 - accuracy: 0.4458 - val_loss: 2.3530 - val_accuracy: 0.4656\n",
      "78/232\n",
      "206/206 [==============================] - 16s 76ms/step - loss: 2.5724 - accuracy: 0.4470 - val_loss: 2.3882 - val_accuracy: 0.4642\n",
      "79/232\n",
      "211/211 [==============================] - 16s 76ms/step - loss: 2.5584 - accuracy: 0.4516 - val_loss: 2.4277 - val_accuracy: 0.4628\n",
      "80/232\n",
      "207/207 [==============================] - 16s 76ms/step - loss: 2.5277 - accuracy: 0.4521 - val_loss: 2.3926 - val_accuracy: 0.4561\n",
      "81/232\n",
      "204/204 [==============================] - 16s 76ms/step - loss: 2.5669 - accuracy: 0.4506 - val_loss: 2.3491 - val_accuracy: 0.4654\n",
      "82/232\n",
      "207/207 [==============================] - 16s 76ms/step - loss: 2.5486 - accuracy: 0.4529 - val_loss: 2.3054 - val_accuracy: 0.4668\n",
      "83/232\n",
      "207/207 [==============================] - 16s 76ms/step - loss: 2.5369 - accuracy: 0.4539 - val_loss: 2.3585 - val_accuracy: 0.4686\n",
      "84/232\n",
      "207/207 [==============================] - 16s 76ms/step - loss: 2.5520 - accuracy: 0.4499 - val_loss: 2.3471 - val_accuracy: 0.4669\n",
      "85/232\n",
      "207/207 [==============================] - 16s 76ms/step - loss: 2.5552 - accuracy: 0.4509 - val_loss: 2.3550 - val_accuracy: 0.4644\n",
      "86/232\n",
      "205/205 [==============================] - 16s 76ms/step - loss: 2.5563 - accuracy: 0.4498 - val_loss: 2.3940 - val_accuracy: 0.4571\n",
      "87/232\n",
      "207/207 [==============================] - 16s 76ms/step - loss: 2.5368 - accuracy: 0.4500 - val_loss: 2.3776 - val_accuracy: 0.4611\n",
      "88/232\n",
      "205/205 [==============================] - 16s 76ms/step - loss: 2.5311 - accuracy: 0.4514 - val_loss: 2.3328 - val_accuracy: 0.4713\n",
      "89/232\n",
      "207/207 [==============================] - 16s 76ms/step - loss: 2.5367 - accuracy: 0.4523 - val_loss: 2.3789 - val_accuracy: 0.4634\n",
      "90/232\n",
      "204/204 [==============================] - 16s 76ms/step - loss: 2.5506 - accuracy: 0.4452 - val_loss: 2.3408 - val_accuracy: 0.4613\n",
      "91/232\n",
      "208/208 [==============================] - 16s 76ms/step - loss: 2.5083 - accuracy: 0.4549 - val_loss: 2.2927 - val_accuracy: 0.4783\n",
      "92/232\n",
      "206/206 [==============================] - 16s 76ms/step - loss: 2.5285 - accuracy: 0.4514 - val_loss: 2.3450 - val_accuracy: 0.4675\n",
      "93/232\n",
      "206/206 [==============================] - 16s 76ms/step - loss: 2.5454 - accuracy: 0.4500 - val_loss: 2.3452 - val_accuracy: 0.4635\n",
      "94/232\n",
      "208/208 [==============================] - 16s 76ms/step - loss: 2.5316 - accuracy: 0.4499 - val_loss: 2.3396 - val_accuracy: 0.4708\n",
      "95/232\n",
      "208/208 [==============================] - 16s 76ms/step - loss: 2.5466 - accuracy: 0.4499 - val_loss: 2.3774 - val_accuracy: 0.4602\n",
      "96/232\n",
      "208/208 [==============================] - 16s 76ms/step - loss: 2.5382 - accuracy: 0.4503 - val_loss: 2.3598 - val_accuracy: 0.4655\n",
      "97/232\n",
      "205/205 [==============================] - 16s 76ms/step - loss: 2.5189 - accuracy: 0.4542 - val_loss: 2.3274 - val_accuracy: 0.4700\n",
      "98/232\n",
      "206/206 [==============================] - 16s 76ms/step - loss: 2.5220 - accuracy: 0.4540 - val_loss: 2.3127 - val_accuracy: 0.4745\n",
      "99/232\n",
      "210/210 [==============================] - 16s 76ms/step - loss: 2.5229 - accuracy: 0.4540 - val_loss: 2.3591 - val_accuracy: 0.4685\n",
      "100/232\n",
      "207/207 [==============================] - 16s 76ms/step - loss: 2.5309 - accuracy: 0.4536 - val_loss: 2.3186 - val_accuracy: 0.4640\n",
      "101/232\n",
      "203/203 [==============================] - 16s 76ms/step - loss: 2.5046 - accuracy: 0.4606 - val_loss: 2.2871 - val_accuracy: 0.4718\n",
      "102/232\n",
      "204/204 [==============================] - 16s 76ms/step - loss: 2.5208 - accuracy: 0.4559 - val_loss: 2.3038 - val_accuracy: 0.4731\n",
      "103/232\n",
      "209/209 [==============================] - 16s 76ms/step - loss: 2.5182 - accuracy: 0.4557 - val_loss: 2.3077 - val_accuracy: 0.4689\n",
      "104/232\n",
      "208/208 [==============================] - 16s 76ms/step - loss: 2.5272 - accuracy: 0.4519 - val_loss: 2.3624 - val_accuracy: 0.4623\n",
      "105/232\n",
      "210/210 [==============================] - 16s 76ms/step - loss: 2.5384 - accuracy: 0.4506 - val_loss: 2.3468 - val_accuracy: 0.4652\n",
      "106/232\n",
      "206/206 [==============================] - 16s 76ms/step - loss: 2.5114 - accuracy: 0.4550 - val_loss: 2.3294 - val_accuracy: 0.4690\n",
      "107/232\n",
      "206/206 [==============================] - 16s 76ms/step - loss: 2.4795 - accuracy: 0.4583 - val_loss: 2.2970 - val_accuracy: 0.4781\n",
      "108/232\n",
      "208/208 [==============================] - 16s 76ms/step - loss: 2.5034 - accuracy: 0.4553 - val_loss: 2.3156 - val_accuracy: 0.4693\n",
      "109/232\n",
      "207/207 [==============================] - 16s 76ms/step - loss: 2.4850 - accuracy: 0.4566 - val_loss: 2.2923 - val_accuracy: 0.4725\n",
      "110/232\n",
      "205/205 [==============================] - 16s 76ms/step - loss: 2.4963 - accuracy: 0.4574 - val_loss: 2.3109 - val_accuracy: 0.4721\n",
      "111/232\n",
      "207/207 [==============================] - 16s 76ms/step - loss: 2.4876 - accuracy: 0.4577 - val_loss: 2.2574 - val_accuracy: 0.4811\n",
      "112/232\n",
      "206/206 [==============================] - 16s 76ms/step - loss: 2.4911 - accuracy: 0.4583 - val_loss: 2.3035 - val_accuracy: 0.4723\n",
      "113/232\n",
      "206/206 [==============================] - 16s 76ms/step - loss: 2.4902 - accuracy: 0.4590 - val_loss: 2.2980 - val_accuracy: 0.4722\n",
      "114/232\n",
      "209/209 [==============================] - 16s 76ms/step - loss: 2.4724 - accuracy: 0.4608 - val_loss: 2.2838 - val_accuracy: 0.4778\n",
      "115/232\n",
      "208/208 [==============================] - 16s 76ms/step - loss: 2.5112 - accuracy: 0.4526 - val_loss: 2.3163 - val_accuracy: 0.4648\n",
      "116/232\n",
      "205/205 [==============================] - 16s 76ms/step - loss: 2.5088 - accuracy: 0.4569 - val_loss: 2.3535 - val_accuracy: 0.4691\n",
      "117/232\n",
      "206/206 [==============================] - 16s 76ms/step - loss: 2.4799 - accuracy: 0.4620 - val_loss: 2.2847 - val_accuracy: 0.4735\n",
      "118/232\n",
      "207/207 [==============================] - 16s 76ms/step - loss: 2.4802 - accuracy: 0.4581 - val_loss: 2.3169 - val_accuracy: 0.4690\n",
      "119/232\n",
      "206/206 [==============================] - 16s 76ms/step - loss: 2.4595 - accuracy: 0.4613 - val_loss: 2.3225 - val_accuracy: 0.4667\n",
      "120/232\n",
      "205/205 [==============================] - 16s 76ms/step - loss: 2.4872 - accuracy: 0.4576 - val_loss: 2.3434 - val_accuracy: 0.4662\n",
      "121/232\n",
      "209/209 [==============================] - 16s 76ms/step - loss: 2.4813 - accuracy: 0.4595 - val_loss: 2.3149 - val_accuracy: 0.4679\n",
      "122/232\n",
      "205/205 [==============================] - 16s 76ms/step - loss: 2.5040 - accuracy: 0.4560 - val_loss: 2.2965 - val_accuracy: 0.4667\n",
      "123/232\n",
      "209/209 [==============================] - 16s 76ms/step - loss: 2.5109 - accuracy: 0.4536 - val_loss: 2.2975 - val_accuracy: 0.4670\n",
      "124/232\n",
      "205/205 [==============================] - 16s 76ms/step - loss: 2.4800 - accuracy: 0.4609 - val_loss: 2.3016 - val_accuracy: 0.4757\n",
      "125/232\n",
      "207/207 [==============================] - 16s 76ms/step - loss: 2.5020 - accuracy: 0.4561 - val_loss: 2.3160 - val_accuracy: 0.4714\n",
      "126/232\n",
      "208/208 [==============================] - 16s 76ms/step - loss: 2.4783 - accuracy: 0.4599 - val_loss: 2.2729 - val_accuracy: 0.4746\n",
      "127/232\n",
      "206/206 [==============================] - 16s 76ms/step - loss: 2.4954 - accuracy: 0.4559 - val_loss: 2.3103 - val_accuracy: 0.4689\n",
      "128/232\n",
      "207/207 [==============================] - 16s 76ms/step - loss: 2.4627 - accuracy: 0.4635 - val_loss: 2.2344 - val_accuracy: 0.4792\n",
      "129/232\n",
      "205/205 [==============================] - 16s 76ms/step - loss: 2.4774 - accuracy: 0.4605 - val_loss: 2.3067 - val_accuracy: 0.4719\n",
      "130/232\n",
      "206/206 [==============================] - 16s 76ms/step - loss: 2.4856 - accuracy: 0.4576 - val_loss: 2.2986 - val_accuracy: 0.4772\n",
      "131/232\n",
      "209/209 [==============================] - 16s 76ms/step - loss: 2.4881 - accuracy: 0.4591 - val_loss: 2.2846 - val_accuracy: 0.4707\n",
      "132/232\n",
      "207/207 [==============================] - 16s 75ms/step - loss: 2.4598 - accuracy: 0.4606 - val_loss: 2.2522 - val_accuracy: 0.4759\n",
      "133/232\n",
      "209/209 [==============================] - 16s 75ms/step - loss: 2.4864 - accuracy: 0.4565 - val_loss: 2.3462 - val_accuracy: 0.4616\n",
      "134/232\n",
      "209/209 [==============================] - 16s 75ms/step - loss: 2.4932 - accuracy: 0.4575 - val_loss: 2.2903 - val_accuracy: 0.4749\n",
      "135/232\n",
      "206/206 [==============================] - 16s 75ms/step - loss: 2.4718 - accuracy: 0.4587 - val_loss: 2.2829 - val_accuracy: 0.4774\n",
      "136/232\n",
      "206/206 [==============================] - 16s 75ms/step - loss: 2.4462 - accuracy: 0.4683 - val_loss: 2.2551 - val_accuracy: 0.4863\n",
      "137/232\n",
      "206/206 [==============================] - 16s 75ms/step - loss: 2.4751 - accuracy: 0.4582 - val_loss: 2.2823 - val_accuracy: 0.4727\n",
      "138/232\n",
      "206/206 [==============================] - 16s 75ms/step - loss: 2.4750 - accuracy: 0.4607 - val_loss: 2.3221 - val_accuracy: 0.4670\n",
      "139/232\n",
      "206/206 [==============================] - 16s 75ms/step - loss: 2.4789 - accuracy: 0.4595 - val_loss: 2.2512 - val_accuracy: 0.4830\n",
      "140/232\n",
      "207/207 [==============================] - 16s 75ms/step - loss: 2.4828 - accuracy: 0.4566 - val_loss: 2.2893 - val_accuracy: 0.4784\n",
      "141/232\n",
      "205/205 [==============================] - 16s 75ms/step - loss: 2.4604 - accuracy: 0.4633 - val_loss: 2.2715 - val_accuracy: 0.4719\n",
      "142/232\n",
      "203/203 [==============================] - 15s 75ms/step - loss: 2.4756 - accuracy: 0.4618 - val_loss: 2.2790 - val_accuracy: 0.4735\n",
      "143/232\n",
      "207/207 [==============================] - 16s 75ms/step - loss: 2.4576 - accuracy: 0.4639 - val_loss: 2.2778 - val_accuracy: 0.4793\n",
      "144/232\n",
      "209/209 [==============================] - 16s 75ms/step - loss: 2.4971 - accuracy: 0.4582 - val_loss: 2.2936 - val_accuracy: 0.4742\n",
      "145/232\n",
      "206/206 [==============================] - 16s 75ms/step - loss: 2.4547 - accuracy: 0.4637 - val_loss: 2.2600 - val_accuracy: 0.4712\n",
      "146/232\n",
      "209/209 [==============================] - 16s 75ms/step - loss: 2.4469 - accuracy: 0.4657 - val_loss: 2.2550 - val_accuracy: 0.4796\n",
      "147/232\n",
      "205/205 [==============================] - 16s 75ms/step - loss: 2.4450 - accuracy: 0.4659 - val_loss: 2.2562 - val_accuracy: 0.4828\n",
      "148/232\n",
      "206/206 [==============================] - 16s 75ms/step - loss: 2.4530 - accuracy: 0.4633 - val_loss: 2.2940 - val_accuracy: 0.4784\n",
      "149/232\n",
      "207/207 [==============================] - 16s 75ms/step - loss: 2.4696 - accuracy: 0.4629 - val_loss: 2.2584 - val_accuracy: 0.4777\n",
      "150/232\n",
      "208/208 [==============================] - 16s 75ms/step - loss: 2.4736 - accuracy: 0.4594 - val_loss: 2.2949 - val_accuracy: 0.4696\n",
      "151/232\n",
      "210/210 [==============================] - 16s 75ms/step - loss: 2.4630 - accuracy: 0.4610 - val_loss: 2.2595 - val_accuracy: 0.4732\n",
      "152/232\n",
      "207/207 [==============================] - 16s 75ms/step - loss: 2.4673 - accuracy: 0.4628 - val_loss: 2.2466 - val_accuracy: 0.4758\n",
      "153/232\n",
      "207/207 [==============================] - 16s 75ms/step - loss: 2.4482 - accuracy: 0.4611 - val_loss: 2.2666 - val_accuracy: 0.4818\n",
      "154/232\n",
      "209/209 [==============================] - 16s 75ms/step - loss: 2.4552 - accuracy: 0.4623 - val_loss: 2.3004 - val_accuracy: 0.4722\n",
      "155/232\n",
      "207/207 [==============================] - 16s 75ms/step - loss: 2.4815 - accuracy: 0.4599 - val_loss: 2.3410 - val_accuracy: 0.4680\n",
      "156/232\n",
      "206/206 [==============================] - 16s 75ms/step - loss: 2.4445 - accuracy: 0.4652 - val_loss: 2.2247 - val_accuracy: 0.4792\n",
      "157/232\n",
      "209/209 [==============================] - 16s 75ms/step - loss: 2.4541 - accuracy: 0.4625 - val_loss: 2.2856 - val_accuracy: 0.4739\n",
      "158/232\n",
      "207/207 [==============================] - 16s 75ms/step - loss: 2.4554 - accuracy: 0.4641 - val_loss: 2.2641 - val_accuracy: 0.4727\n",
      "159/232\n",
      "205/205 [==============================] - 16s 75ms/step - loss: 2.4370 - accuracy: 0.4672 - val_loss: 2.2319 - val_accuracy: 0.4885\n",
      "160/232\n",
      "204/204 [==============================] - 15s 75ms/step - loss: 2.4422 - accuracy: 0.4664 - val_loss: 2.2473 - val_accuracy: 0.4844\n",
      "161/232\n",
      "206/206 [==============================] - 16s 75ms/step - loss: 2.4428 - accuracy: 0.4653 - val_loss: 2.2383 - val_accuracy: 0.4783\n",
      "162/232\n",
      "206/206 [==============================] - 16s 75ms/step - loss: 2.4481 - accuracy: 0.4644 - val_loss: 2.2396 - val_accuracy: 0.4802\n",
      "163/232\n",
      "205/205 [==============================] - 16s 75ms/step - loss: 2.4355 - accuracy: 0.4655 - val_loss: 2.1835 - val_accuracy: 0.4884\n",
      "164/232\n",
      "207/207 [==============================] - 16s 75ms/step - loss: 2.4424 - accuracy: 0.4636 - val_loss: 2.2390 - val_accuracy: 0.4801\n",
      "165/232\n",
      "208/208 [==============================] - 16s 75ms/step - loss: 2.4316 - accuracy: 0.4677 - val_loss: 2.2338 - val_accuracy: 0.4813\n",
      "166/232\n",
      "206/206 [==============================] - 16s 75ms/step - loss: 2.4542 - accuracy: 0.4644 - val_loss: 2.2503 - val_accuracy: 0.4811\n",
      "167/232\n",
      "210/210 [==============================] - 16s 75ms/step - loss: 2.4339 - accuracy: 0.4671 - val_loss: 2.2774 - val_accuracy: 0.4776\n",
      "168/232\n",
      "207/207 [==============================] - 16s 75ms/step - loss: 2.4207 - accuracy: 0.4686 - val_loss: 2.2141 - val_accuracy: 0.4814\n",
      "169/232\n",
      "204/204 [==============================] - 15s 75ms/step - loss: 2.4086 - accuracy: 0.4723 - val_loss: 2.2111 - val_accuracy: 0.4858\n",
      "170/232\n",
      "209/209 [==============================] - 16s 75ms/step - loss: 2.4474 - accuracy: 0.4655 - val_loss: 2.3033 - val_accuracy: 0.4687\n",
      "171/232\n",
      "205/205 [==============================] - 16s 75ms/step - loss: 2.4296 - accuracy: 0.4678 - val_loss: 2.2693 - val_accuracy: 0.4758\n",
      "172/232\n",
      "208/208 [==============================] - 16s 75ms/step - loss: 2.4849 - accuracy: 0.4558 - val_loss: 2.2677 - val_accuracy: 0.4671\n",
      "173/232\n",
      "204/204 [==============================] - 15s 75ms/step - loss: 2.4352 - accuracy: 0.4654 - val_loss: 2.2274 - val_accuracy: 0.4845\n",
      "174/232\n",
      "203/203 [==============================] - 15s 75ms/step - loss: 2.4381 - accuracy: 0.4643 - val_loss: 2.2402 - val_accuracy: 0.4762\n",
      "175/232\n",
      "206/206 [==============================] - 16s 75ms/step - loss: 2.4323 - accuracy: 0.4693 - val_loss: 2.2194 - val_accuracy: 0.4880\n",
      "176/232\n",
      "207/207 [==============================] - 16s 75ms/step - loss: 2.4240 - accuracy: 0.4679 - val_loss: 2.2197 - val_accuracy: 0.4837\n",
      "177/232\n",
      "205/205 [==============================] - 15s 75ms/step - loss: 2.4190 - accuracy: 0.4688 - val_loss: 2.2025 - val_accuracy: 0.4886\n",
      "178/232\n",
      "207/207 [==============================] - 16s 75ms/step - loss: 2.4355 - accuracy: 0.4649 - val_loss: 2.2216 - val_accuracy: 0.4775\n",
      "179/232\n",
      "207/207 [==============================] - 16s 75ms/step - loss: 2.4472 - accuracy: 0.4620 - val_loss: 2.2430 - val_accuracy: 0.4783\n",
      "180/232\n",
      "206/206 [==============================] - 16s 75ms/step - loss: 2.4320 - accuracy: 0.4675 - val_loss: 2.1792 - val_accuracy: 0.4904\n",
      "181/232\n",
      "207/207 [==============================] - 16s 75ms/step - loss: 2.4496 - accuracy: 0.4613 - val_loss: 2.2114 - val_accuracy: 0.4870\n",
      "182/232\n",
      "207/207 [==============================] - 16s 75ms/step - loss: 2.4241 - accuracy: 0.4669 - val_loss: 2.2238 - val_accuracy: 0.4869\n",
      "183/232\n",
      "206/206 [==============================] - 16s 75ms/step - loss: 2.4186 - accuracy: 0.4681 - val_loss: 2.2051 - val_accuracy: 0.4883\n",
      "184/232\n",
      "205/205 [==============================] - 16s 75ms/step - loss: 2.4069 - accuracy: 0.4679 - val_loss: 2.1722 - val_accuracy: 0.4894\n",
      "185/232\n",
      "207/207 [==============================] - 16s 75ms/step - loss: 2.4370 - accuracy: 0.4634 - val_loss: 2.2579 - val_accuracy: 0.4782\n",
      "186/232\n",
      "206/206 [==============================] - 16s 75ms/step - loss: 2.4037 - accuracy: 0.4719 - val_loss: 2.2160 - val_accuracy: 0.4765\n",
      "187/232\n",
      "206/206 [==============================] - 16s 75ms/step - loss: 2.4126 - accuracy: 0.4687 - val_loss: 2.1770 - val_accuracy: 0.4897\n",
      "188/232\n",
      "205/205 [==============================] - 16s 75ms/step - loss: 2.4080 - accuracy: 0.4714 - val_loss: 2.2006 - val_accuracy: 0.4882\n",
      "189/232\n",
      "208/208 [==============================] - 16s 75ms/step - loss: 2.4482 - accuracy: 0.4633 - val_loss: 2.1994 - val_accuracy: 0.4855\n",
      "190/232\n",
      "206/206 [==============================] - 16s 75ms/step - loss: 2.4446 - accuracy: 0.4642 - val_loss: 2.2639 - val_accuracy: 0.4756\n",
      "191/232\n",
      "205/205 [==============================] - 16s 75ms/step - loss: 2.4324 - accuracy: 0.4676 - val_loss: 2.2139 - val_accuracy: 0.4811\n",
      "192/232\n",
      "208/208 [==============================] - 16s 75ms/step - loss: 2.4040 - accuracy: 0.4702 - val_loss: 2.2133 - val_accuracy: 0.4852\n",
      "193/232\n",
      "205/205 [==============================] - 16s 75ms/step - loss: 2.4224 - accuracy: 0.4677 - val_loss: 2.2249 - val_accuracy: 0.4826\n",
      "194/232\n",
      "208/208 [==============================] - 16s 75ms/step - loss: 2.4060 - accuracy: 0.4706 - val_loss: 2.2086 - val_accuracy: 0.4842\n",
      "195/232\n",
      "205/205 [==============================] - 16s 75ms/step - loss: 2.4002 - accuracy: 0.4702 - val_loss: 2.1818 - val_accuracy: 0.4872\n",
      "196/232\n",
      "206/206 [==============================] - 16s 75ms/step - loss: 2.4303 - accuracy: 0.4650 - val_loss: 2.3079 - val_accuracy: 0.4688\n",
      "197/232\n",
      "205/205 [==============================] - 16s 75ms/step - loss: 2.4053 - accuracy: 0.4708 - val_loss: 2.2011 - val_accuracy: 0.4954\n",
      "198/232\n",
      "203/203 [==============================] - 15s 75ms/step - loss: 2.4083 - accuracy: 0.4728 - val_loss: 2.2400 - val_accuracy: 0.4873\n",
      "199/232\n",
      "206/206 [==============================] - 16s 75ms/step - loss: 2.4005 - accuracy: 0.4699 - val_loss: 2.1855 - val_accuracy: 0.4921\n",
      "200/232\n",
      "206/206 [==============================] - 16s 75ms/step - loss: 2.4186 - accuracy: 0.4662 - val_loss: 2.2197 - val_accuracy: 0.4803\n",
      "201/232\n",
      "206/206 [==============================] - 16s 75ms/step - loss: 2.3958 - accuracy: 0.4706 - val_loss: 2.2302 - val_accuracy: 0.4889\n",
      "202/232\n",
      "207/207 [==============================] - 16s 75ms/step - loss: 2.3932 - accuracy: 0.4713 - val_loss: 2.1931 - val_accuracy: 0.4908\n",
      "203/232\n",
      "205/205 [==============================] - 16s 75ms/step - loss: 2.4121 - accuracy: 0.4681 - val_loss: 2.2147 - val_accuracy: 0.4842\n",
      "204/232\n",
      "206/206 [==============================] - 16s 75ms/step - loss: 2.4491 - accuracy: 0.4614 - val_loss: 2.2546 - val_accuracy: 0.4813\n",
      "205/232\n",
      "209/209 [==============================] - 16s 75ms/step - loss: 2.3991 - accuracy: 0.4710 - val_loss: 2.2246 - val_accuracy: 0.4879\n",
      "206/232\n",
      "206/206 [==============================] - 16s 75ms/step - loss: 2.4250 - accuracy: 0.4649 - val_loss: 2.1937 - val_accuracy: 0.4895\n",
      "207/232\n",
      "205/205 [==============================] - 16s 75ms/step - loss: 2.4160 - accuracy: 0.4671 - val_loss: 2.1921 - val_accuracy: 0.4904\n",
      "208/232\n",
      "207/207 [==============================] - 16s 75ms/step - loss: 2.4102 - accuracy: 0.4692 - val_loss: 2.2229 - val_accuracy: 0.4785\n",
      "209/232\n",
      "206/206 [==============================] - 16s 75ms/step - loss: 2.4246 - accuracy: 0.4662 - val_loss: 2.2455 - val_accuracy: 0.4860\n",
      "210/232\n",
      "203/203 [==============================] - 15s 75ms/step - loss: 2.4016 - accuracy: 0.4705 - val_loss: 2.2014 - val_accuracy: 0.4835\n",
      "211/232\n",
      "206/206 [==============================] - 16s 75ms/step - loss: 2.4073 - accuracy: 0.4705 - val_loss: 2.2091 - val_accuracy: 0.4839\n",
      "212/232\n",
      "207/207 [==============================] - 16s 75ms/step - loss: 2.4235 - accuracy: 0.4659 - val_loss: 2.2282 - val_accuracy: 0.4849\n",
      "213/232\n",
      "208/208 [==============================] - 16s 75ms/step - loss: 2.4160 - accuracy: 0.4719 - val_loss: 2.2221 - val_accuracy: 0.4867\n",
      "214/232\n",
      "206/206 [==============================] - 16s 75ms/step - loss: 2.3922 - accuracy: 0.4718 - val_loss: 2.2016 - val_accuracy: 0.4834\n",
      "215/232\n",
      "204/204 [==============================] - 15s 75ms/step - loss: 2.3898 - accuracy: 0.4730 - val_loss: 2.1990 - val_accuracy: 0.4829\n",
      "216/232\n",
      "204/204 [==============================] - 15s 75ms/step - loss: 2.3966 - accuracy: 0.4732 - val_loss: 2.1888 - val_accuracy: 0.4905\n",
      "217/232\n",
      "206/206 [==============================] - 16s 75ms/step - loss: 2.4016 - accuracy: 0.4695 - val_loss: 2.2353 - val_accuracy: 0.4859\n",
      "218/232\n",
      "207/207 [==============================] - 16s 75ms/step - loss: 2.4389 - accuracy: 0.4622 - val_loss: 2.2127 - val_accuracy: 0.4779\n",
      "219/232\n",
      "205/205 [==============================] - 16s 75ms/step - loss: 2.4016 - accuracy: 0.4686 - val_loss: 2.2138 - val_accuracy: 0.4805\n",
      "220/232\n",
      "206/206 [==============================] - 16s 75ms/step - loss: 2.4039 - accuracy: 0.4695 - val_loss: 2.2247 - val_accuracy: 0.4808\n",
      "221/232\n",
      "207/207 [==============================] - 16s 75ms/step - loss: 2.4166 - accuracy: 0.4659 - val_loss: 2.2440 - val_accuracy: 0.4798\n",
      "222/232\n",
      "205/205 [==============================] - 16s 75ms/step - loss: 2.3919 - accuracy: 0.4696 - val_loss: 2.2162 - val_accuracy: 0.4873\n",
      "223/232\n",
      "207/207 [==============================] - 16s 75ms/step - loss: 2.3891 - accuracy: 0.4731 - val_loss: 2.1616 - val_accuracy: 0.4912\n",
      "224/232\n",
      "207/207 [==============================] - 16s 75ms/step - loss: 2.4014 - accuracy: 0.4705 - val_loss: 2.2135 - val_accuracy: 0.4869\n",
      "225/232\n",
      "203/203 [==============================] - 15s 75ms/step - loss: 2.3851 - accuracy: 0.4728 - val_loss: 2.1863 - val_accuracy: 0.4862\n",
      "226/232\n",
      "202/202 [==============================] - 15s 75ms/step - loss: 2.3738 - accuracy: 0.4742 - val_loss: 2.1196 - val_accuracy: 0.5022\n",
      "227/232\n",
      "209/209 [==============================] - 16s 75ms/step - loss: 2.4200 - accuracy: 0.4657 - val_loss: 2.2125 - val_accuracy: 0.4844\n",
      "228/232\n",
      "208/208 [==============================] - 16s 75ms/step - loss: 2.4149 - accuracy: 0.4679 - val_loss: 2.2062 - val_accuracy: 0.4817\n",
      "229/232\n",
      "208/208 [==============================] - 16s 75ms/step - loss: 2.4088 - accuracy: 0.4683 - val_loss: 2.2143 - val_accuracy: 0.4847\n",
      "230/232\n",
      "203/203 [==============================] - 15s 75ms/step - loss: 2.3948 - accuracy: 0.4683 - val_loss: 2.2001 - val_accuracy: 0.4853\n",
      "231/232\n",
      "205/205 [==============================] - 16s 75ms/step - loss: 2.4001 - accuracy: 0.4694 - val_loss: 2.2163 - val_accuracy: 0.4819\n",
      "232/232\n",
      "93/93 [==============================] - 7s 77ms/step - loss: 2.4049 - accuracy: 0.4712 - val_loss: 2.1942 - val_accuracy: 0.4836\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 512  # Adjust this if needed\n",
    "batchs = math.ceil(len(games) / batch_size)\n",
    "\n",
    "# Set up TensorBoard callback\n",
    "tensorboard_callback = TensorBoard(log_dir=f\"kyu_logs/{time.time()}\", histogram_freq=1)\n",
    "\n",
    "for epoch in range(1, 2):\n",
    "    print(\"epoch\", epoch)\n",
    "    batch_count = 1\n",
    "    \n",
    "    for x_train, y_train, x_val, y_val in data_generator(games, batch_size):\n",
    "        print(f\"{batch_count}/{batchs}\")\n",
    "        history = model.fit(\n",
    "            x=x_train, \n",
    "            y=y_train,\n",
    "            batch_size=1024,\n",
    "            epochs=1,\n",
    "            validation_data=(x_val, y_val),\n",
    "            callbacks=[tensorboard_callback]  # Add TensorBoard callback here\n",
    "        )\n",
    "\n",
    "        if batch_count % 10 == 0:\n",
    "            model.save(f\"./models/kyu_{batch_count}_{history.history['val_accuracy'][0]:.5f}_{history.history['val_loss'][0]:.5f}.h5\")\n",
    "\n",
    "        batch_count += 1\n",
    "        reset_keras()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5254359",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# batch_size = 512  # Adjust this if needed\n",
    "# batchs = math.ceil(len(games)/batch_size)\n",
    "\n",
    "# for epoch in range(1, 2):\n",
    "#     print(\"epoch\", epoch)\n",
    "#     batch_count = 1\n",
    "    \n",
    "#     for x_train, y_train, x_val, y_val in data_generator(games, batch_size):\n",
    "#         print(f\"{batch_count}/{batchs}\")\n",
    "#         history = model.fit(\n",
    "#             x=x_train, \n",
    "#             y=y_train,\n",
    "#             batch_size=batch_size,\n",
    "#             epochs=1,\n",
    "#             validation_data=(x_val, y_val),\n",
    "#         )\n",
    "\n",
    "#         if batch_count % 10 == 0:\n",
    "#             model.save(\"./models/kyu_\" + str(batch_count) + \"_\"+ str(history.history['val_accuracy'][0])[:5] + \"_\" + str(history.history['val_loss'][0])[:5] + \".h5\")\n",
    "\n",
    "#         batch_count += 1\n",
    "#         reset_keras()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "584d2bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc: [0.4835520088672638]\n"
     ]
    }
   ],
   "source": [
    "print(\"val_acc:\", history.history['val_accuracy'])\n",
    "model.save(f'./models/model_kyu2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215959fd",
   "metadata": {},
   "source": [
    "## without data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "71fbcaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 400\n",
    "# batch = 1\n",
    "\n",
    "# for batch_start in range(0, 20000, batch_size):\n",
    "#     print(\"epoch\", batch)\n",
    "#     batch_end = batch_start + batch_size\n",
    "#     batch_games = games[batch_start:batch_end]\n",
    "#     x = []\n",
    "#     y = []\n",
    "#     for game in batch_games:\n",
    "#         moves_list = game.split(',')\n",
    "#         for count, move in enumerate(moves_list):\n",
    "#             x.append(prepare_input(moves_list[:count]))\n",
    "#             y.append(prepare_label(moves_list[count]))\n",
    "\n",
    "#     x = np.array(x)\n",
    "#     y = np.array(y)\n",
    "\n",
    "#     y_one_hot = tf.one_hot(y, depth=19*19)\n",
    "\n",
    "#     x_train, x_val, y_train, y_val = train_test_split(x, y_one_hot.numpy(), test_size=0.10)\n",
    "    \n",
    "#     history = model.fit(\n",
    "#         x = x_train, \n",
    "#         y = y_train,\n",
    "#         batch_size = 128,\n",
    "#         epochs = 1,\n",
    "#         validation_data=(x_val, y_val),\n",
    "#     )\n",
    "#     print(\"val_acc:\", history.history['val_accuracy'])\n",
    "\n",
    "#     if batch % 10 == 0:\n",
    "#         model.save(\"./models/kyu_\" + str(batch) + \"_\"+ str(history.history['val_accuracy'][0])[:5] + \"_\" + str(history.history['val_loss'][0])[:5] + \".h5\")\n",
    "    \n",
    "#     tf.keras.backend.clear_session()\n",
    "#     del history\n",
    "#     batch += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e5a6a278",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.config.experimental.reset_memory_stats('GPU:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2aaddf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./model_kyu_tutorial.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484be28d",
   "metadata": {},
   "source": [
    "## ALL DONE!\n",
    "\n",
    "For using the model and creating a submission file, follow the notebook **Create Public Upload CSV.ipynb**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7fafaa",
   "metadata": {},
   "source": [
    "# End of Tutorial\n",
    "\n",
    "You are free to use more modern NN architectures, a better pre-processing, feature extraction methods to achieve much better accuracy!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
