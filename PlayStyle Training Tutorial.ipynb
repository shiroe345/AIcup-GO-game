{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bd5077d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, Flatten, Dense, Softmax, BatchNormalization, Dropout, Add\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4d54d124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.10.0'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "154db11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if len(physical_devices) == 0:\n",
    "    print(\"No GPU devices found. Using CPU.\")\n",
    "else:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5666d92a",
   "metadata": {},
   "source": [
    "# Data Pre-Processing\n",
    "\n",
    "Open **play_style_train.csv** file and split the games into a list.\n",
    "Every row of csv: `PSL0000000001,1,B[pd],W[dp],B[qp],W[dc],B[nq],W[nc],B[qf],W[kd],B[ce],W[dg],B[dd],W[cc],B[fd],W[ed],B[ee],W[ec],B[ge],W[gc],B[di]`. \n",
    "\n",
    "Columns are:\n",
    "\n",
    "    1. PSL0000000001: Game ID\n",
    "    2. 1: Game Style\n",
    "    3-... : Moves, the last move represents the play style (B[di] in this case)\n",
    "    \n",
    "We cropped only the moves to game list as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e4b559ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B[pd],W[dp],B[dd],W[qp],B[op],W[pn],B[qq],W[rq],B[rr],W[pq],B[qr],W[pp],B[rp],W[ro],B[sq],W[pr],B[fq],W[jp],B[cq],W[dq],B[cp],W[do],B[dr] 3\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "df = open('./Training Dataset/play_style_train.csv').read().splitlines()\n",
    "random.shuffle(df)\n",
    "games = [i.split(',',2)[-1] for i in df]\n",
    "game_styles = [int(i.split(',',2)[-2]) for i in df]\n",
    "print(games[0], game_styles[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f64af3",
   "metadata": {},
   "source": [
    "Create a dictionary to convert the coordinates from characters to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3b52349a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0,\n",
       " 'b': 1,\n",
       " 'c': 2,\n",
       " 'd': 3,\n",
       " 'e': 4,\n",
       " 'f': 5,\n",
       " 'g': 6,\n",
       " 'h': 7,\n",
       " 'i': 8,\n",
       " 'j': 9,\n",
       " 'k': 10,\n",
       " 'l': 11,\n",
       " 'm': 12,\n",
       " 'n': 13,\n",
       " 'o': 14,\n",
       " 'p': 15,\n",
       " 'q': 16,\n",
       " 'r': 17,\n",
       " 's': 18}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = 'abcdefghijklmnopqrs'\n",
    "coordinates = {k:v for v,k in enumerate(chars)}\n",
    "coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3429687",
   "metadata": {},
   "source": [
    "We decided to build a DCNN model in this tutorial. We create data samples by using every move in every game, meaning that the target is to predict the next move by feeding the previous state of the table in every game for every move. Therefore, we can collect much more data samples from games.\n",
    "\n",
    "For the simplicity, we used 2 dimensional feature map to represent the data as below:\n",
    " 1. Occupied areas: mark them as 1 and the empty places as 0\n",
    " 2. The last move in the table: mark the position of the last move as 1 and the rest as 0\n",
    " \n",
    "The target is to predict the game style (1, 2 or 3) from the state of the game table. Later this will be one-hot encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7b28ab61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def prepare_input(moves):\n",
    "#     x = np.zeros((19,19,2))\n",
    "#     for move in moves:\n",
    "#         color = move[0]\n",
    "#         column = coordinates[move[2]]\n",
    "#         row = coordinates[move[3]]\n",
    "#         x[row,column,0] = 1\n",
    "#     if moves:\n",
    "#         last_move_column = coordinates[moves[-1][2]]\n",
    "#         last_move_row = coordinates[moves[-1][3]]\n",
    "#         x[row,column,1] = 1\n",
    "#     return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cd5074b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input(moves):\n",
    "    x = np.zeros((19,19,4))\n",
    "    for move in moves:\n",
    "        color = move[0]\n",
    "        column = coordinates[move[2]]\n",
    "        row = coordinates[move[3]]\n",
    "        if color == 'B':\n",
    "            x[row,column,0] = 1\n",
    "            x[row,column,2] = 1\n",
    "        if color == 'W':\n",
    "            x[row,column,1] = 1\n",
    "            x[row,column,2] = 1\n",
    "    if moves:\n",
    "        last_move_column = coordinates[moves[-1][2]]\n",
    "        last_move_row = coordinates[moves[-1][3]]\n",
    "        x[last_move_row,last_move_column,3] = 1\n",
    "    x[:,:,2] = np.where(x[:,:,2] == 0, 1, 0)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a1a544a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Games: 26615\n"
     ]
    }
   ],
   "source": [
    "# Check how many samples can be obtained\n",
    "n_games = 0\n",
    "for game in games:\n",
    "    n_games += 1\n",
    "print(f\"Total Games: {n_games}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe30773a",
   "metadata": {},
   "source": [
    "Since play style training has smaller dataset comparing to kyu or dan training, we can put the complete dataset to memory. Still, it is better to create a data generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "40cce4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "for game in games:\n",
    "    moves_list = game.split(',')\n",
    "    x.append(prepare_input(moves_list))\n",
    "x = np.array(x)\n",
    "y = np.array(game_styles)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "74d9b37d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26615, 19, 19, 4)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0ad8b3fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26615,)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7f20561a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8184, 9403, 9028], dtype=int64)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c86e70",
   "metadata": {},
   "source": [
    "Target is one-hot encoded and loss is changed to `categorical_crossentropy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "54f30621",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hot = tf.one_hot(y, depth=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ae1a16",
   "metadata": {},
   "source": [
    "Dataset splitting: 90% Training, 10% validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b80a8a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x, y_hot.numpy(), test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8964d8",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "### Simple DCNN Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d8a5f696",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import gc\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "166618d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 10952), started 5 days, 6:55:35 ago. (Use '!kill 10952' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-9c91008532dca7a7\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-9c91008532dca7a7\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=path/to/logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ad6d4040",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    inputs = Input(shape=(19, 19, 2))\n",
    "    outputs = Conv2D(kernel_size=7, filters=256, padding='same', activation='relu')(inputs)\n",
    "    outputs = BatchNormalization()(outputs)\n",
    "    outputs = Conv2D(kernel_size=7, filters=256, padding='same', activation='relu')(outputs)\n",
    "    outputs = BatchNormalization()(outputs)\n",
    "    outputs = Conv2D(kernel_size=5, filters=256, padding='same', activation='relu')(outputs)\n",
    "    outputs = BatchNormalization()(outputs)\n",
    "    outputs = Conv2D(kernel_size=5, filters=256, padding='same', activation='relu')(outputs)\n",
    "    outputs = BatchNormalization()(outputs)\n",
    "    outputs = Conv2D(kernel_size=3, filters=256, padding='same', activation='relu')(outputs)\n",
    "    outputs = BatchNormalization()(outputs)\n",
    "    outputs = Conv2D(kernel_size=3, filters=256, padding='same', activation='relu')(outputs)\n",
    "    outputs = BatchNormalization()(outputs)\n",
    "    outputs = Conv2D(kernel_size=3, filters=1, padding='same', activation='relu')(outputs)\n",
    "    outputs = BatchNormalization()(outputs)\n",
    "    outputs = Flatten()(outputs)\n",
    "    \n",
    "    outputs = Dense(32, activation='relu')(outputs)\n",
    "    outputs = Dropout(0.6)(outputs)\n",
    "    outputs = Dense(3, activation='softmax', )(outputs)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    opt = Adam(learning_rate=0.00005)\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "71d092c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_model():\n",
    "#     inputs = Input(shape=(19, 19, 2))\n",
    "#     outputs = Conv2D(kernel_size=7, filters=32, padding='same', activation='relu')(inputs)\n",
    "#     outputs = BatchNormalization()(outputs)\n",
    "#     outputs = Conv2D(kernel_size=7, filters=32, padding='same', activation='relu')(outputs)\n",
    "#     outputs = BatchNormalization()(outputs)\n",
    "#     outputs = Conv2D(kernel_size=5, filters=32, padding='same', activation='relu')(outputs)\n",
    "#     outputs = BatchNormalization()(outputs)\n",
    "#     outputs = Conv2D(kernel_size=5, filters=32, padding='same', activation='relu')(outputs)\n",
    "#     outputs = BatchNormalization()(outputs)\n",
    "#     outputs = Conv2D(kernel_size=3, filters=32, padding='same', activation='relu')(outputs)\n",
    "#     outputs = BatchNormalization()(outputs)\n",
    "#     outputs = Conv2D(kernel_size=3, filters=32, padding='same', activation='relu')(outputs)\n",
    "#     outputs = BatchNormalization()(outputs)\n",
    "#     outputs = Conv2D(kernel_size=3, filters=1, padding='same', activation='relu')(outputs)\n",
    "#     outputs = BatchNormalization()(outputs)\n",
    "#     outputs = Flatten()(outputs)\n",
    "#     outputs = Dense(32, activation='relu')(outputs)\n",
    "#     outputs = BatchNormalization()(outputs)\n",
    "#     outputs = Dense(32, activation='relu')(outputs)\n",
    "#     outputs = BatchNormalization()(outputs)\n",
    "#     outputs = Dense(3, activation='softmax', )(outputs)\n",
    "#     model = Model(inputs, outputs)\n",
    "#     opt = Adam(learning_rate=0.00005)\n",
    "#     model.compile(optimizer=opt,\n",
    "#                   loss='categorical_crossentropy',\n",
    "#                   metrics=['accuracy'])\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "69cde4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model2():\n",
    "    inputs = Input(shape=(19, 19, 4))\n",
    "\n",
    "    outputs = Conv2D(kernel_size=7, filters=64, padding='same', activation='relu')(inputs)\n",
    "    outputs = BatchNormalization()(outputs)\n",
    "    outputs = Conv2D(kernel_size=7, filters=64, padding='same', activation='relu')(outputs)\n",
    "    outputs = BatchNormalization()(outputs)\n",
    "    outputs = Conv2D(kernel_size=5, filters=64, padding='same', activation='relu')(outputs)\n",
    "    outputs = BatchNormalization()(outputs)\n",
    "    outputs = Conv2D(kernel_size=5, filters=64, padding='same', activation='relu')(outputs)\n",
    "    outputs = BatchNormalization()(outputs)\n",
    "    outputs = Conv2D(kernel_size=3, filters=64, padding='same', activation='relu')(outputs)\n",
    "    outputs = BatchNormalization()(outputs)\n",
    "    outputs = Conv2D(kernel_size=3, filters=1, padding='same', activation='relu')(outputs)\n",
    "    outputs = BatchNormalization()(outputs)\n",
    "    \n",
    "    outputs = Flatten()(outputs)\n",
    "    outputs = Dense(256, activation='relu')(outputs)\n",
    "    outputs = Dropout(0.6)(outputs)\n",
    "    outputs = Dense(3, activation='softmax')(outputs)  # Adjust the number of units based on your output space\n",
    "    model = Model(inputs, outputs)\n",
    "    \n",
    "    opt = Adam(learning_rate=0.001)  # Adjust the learning rate\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss='categorical_crossentropy',  # Change to sparse_categorical_crossentropy\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "295280dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 19, 19, 4)]       0         \n",
      "                                                                 \n",
      " conv2d_52 (Conv2D)          (None, 19, 19, 64)        12608     \n",
      "                                                                 \n",
      " batch_normalization_55 (Bat  (None, 19, 19, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_53 (Conv2D)          (None, 19, 19, 64)        200768    \n",
      "                                                                 \n",
      " batch_normalization_56 (Bat  (None, 19, 19, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_54 (Conv2D)          (None, 19, 19, 64)        102464    \n",
      "                                                                 \n",
      " batch_normalization_57 (Bat  (None, 19, 19, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_55 (Conv2D)          (None, 19, 19, 64)        102464    \n",
      "                                                                 \n",
      " batch_normalization_58 (Bat  (None, 19, 19, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_56 (Conv2D)          (None, 19, 19, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_59 (Bat  (None, 19, 19, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_57 (Conv2D)          (None, 19, 19, 1)         577       \n",
      "                                                                 \n",
      " batch_normalization_60 (Bat  (None, 19, 19, 1)        4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 361)               0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 256)               92672     \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 3)                 771       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 550,536\n",
      "Trainable params: 549,894\n",
      "Non-trainable params: 642\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model2()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4c826c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   1/1647 [..............................] - ETA: 19:46 - loss: 3.0727 - accuracy: 0.2500WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0070s vs `on_train_batch_end` time: 0.0102s). Check your callbacks.\n",
      "1647/1647 [==============================] - 15s 9ms/step - loss: 1.1164 - accuracy: 0.3845 - val_loss: 1.1277 - val_accuracy: 0.3071\n",
      "Epoch 2/30\n",
      "1647/1647 [==============================] - 15s 9ms/step - loss: 1.0630 - accuracy: 0.4249 - val_loss: 1.0433 - val_accuracy: 0.4944\n",
      "Epoch 3/30\n",
      "1647/1647 [==============================] - 14s 9ms/step - loss: 0.9874 - accuracy: 0.5133 - val_loss: 0.9514 - val_accuracy: 0.5206\n",
      "Epoch 4/30\n",
      "1647/1647 [==============================] - 15s 9ms/step - loss: 0.9711 - accuracy: 0.5277 - val_loss: 0.9580 - val_accuracy: 0.5206\n",
      "Epoch 5/30\n",
      "1647/1647 [==============================] - 15s 9ms/step - loss: 0.9613 - accuracy: 0.5356 - val_loss: 0.9388 - val_accuracy: 0.5318\n",
      "Epoch 6/30\n",
      "1647/1647 [==============================] - 15s 9ms/step - loss: 0.9555 - accuracy: 0.5393 - val_loss: 0.9258 - val_accuracy: 0.5693\n",
      "Epoch 7/30\n",
      "1647/1647 [==============================] - 15s 9ms/step - loss: 0.9482 - accuracy: 0.5441 - val_loss: 0.9413 - val_accuracy: 0.5506\n",
      "Epoch 8/30\n",
      "1647/1647 [==============================] - 15s 9ms/step - loss: 0.9357 - accuracy: 0.5532 - val_loss: 0.9993 - val_accuracy: 0.5393\n",
      "Epoch 9/30\n",
      "1647/1647 [==============================] - 15s 9ms/step - loss: 0.9247 - accuracy: 0.5643 - val_loss: 0.9314 - val_accuracy: 0.5393\n",
      "Epoch 10/30\n",
      "1647/1647 [==============================] - 14s 9ms/step - loss: 0.9067 - accuracy: 0.5765 - val_loss: 0.8869 - val_accuracy: 0.5618\n",
      "Epoch 11/30\n",
      "1647/1647 [==============================] - 14s 9ms/step - loss: 0.8666 - accuracy: 0.6105 - val_loss: 0.8131 - val_accuracy: 0.6629\n",
      "Epoch 12/30\n",
      "1647/1647 [==============================] - 14s 9ms/step - loss: 0.8136 - accuracy: 0.6519 - val_loss: 0.7761 - val_accuracy: 0.6667\n",
      "Epoch 13/30\n",
      "1647/1647 [==============================] - 14s 8ms/step - loss: 0.7801 - accuracy: 0.6698 - val_loss: 0.7916 - val_accuracy: 0.6816\n",
      "Epoch 14/30\n",
      "1647/1647 [==============================] - 15s 9ms/step - loss: 0.7561 - accuracy: 0.6844 - val_loss: 0.8153 - val_accuracy: 0.6292\n",
      "Epoch 15/30\n",
      "1647/1647 [==============================] - 14s 9ms/step - loss: 0.7248 - accuracy: 0.6963 - val_loss: 0.7483 - val_accuracy: 0.7041\n",
      "Epoch 16/30\n",
      "1647/1647 [==============================] - 15s 9ms/step - loss: 0.6921 - accuracy: 0.7123 - val_loss: 0.7921 - val_accuracy: 0.7116\n",
      "Epoch 17/30\n",
      "1647/1647 [==============================] - 14s 9ms/step - loss: 0.6573 - accuracy: 0.7274 - val_loss: 0.7838 - val_accuracy: 0.6779\n",
      "Epoch 18/30\n",
      "1647/1647 [==============================] - 14s 9ms/step - loss: 0.6205 - accuracy: 0.7431 - val_loss: 0.8319 - val_accuracy: 0.7004\n",
      "Epoch 19/30\n",
      "1647/1647 [==============================] - 14s 9ms/step - loss: 0.5828 - accuracy: 0.7598 - val_loss: 0.9278 - val_accuracy: 0.6816\n",
      "Epoch 20/30\n",
      "1647/1647 [==============================] - 14s 9ms/step - loss: 0.5409 - accuracy: 0.7750 - val_loss: 0.8360 - val_accuracy: 0.6742\n",
      "Epoch 21/30\n",
      "1647/1647 [==============================] - 15s 9ms/step - loss: 0.5107 - accuracy: 0.7904 - val_loss: 0.8338 - val_accuracy: 0.7116\n",
      "Epoch 22/30\n",
      "1647/1647 [==============================] - 14s 9ms/step - loss: 0.4841 - accuracy: 0.7980 - val_loss: 0.9109 - val_accuracy: 0.6742\n",
      "Epoch 23/30\n",
      "1647/1647 [==============================] - 15s 9ms/step - loss: 0.4495 - accuracy: 0.8141 - val_loss: 0.9266 - val_accuracy: 0.6667\n",
      "Epoch 24/30\n",
      "1647/1647 [==============================] - 19s 11ms/step - loss: 0.4228 - accuracy: 0.8236 - val_loss: 1.1248 - val_accuracy: 0.6554\n",
      "Epoch 25/30\n",
      " 999/1647 [=================>............] - ETA: 10s - loss: 0.3954 - accuracy: 0.8347"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[87], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Create an instance of the SaveModelCallback\u001b[39;00m\n\u001b[0;32m      9\u001b[0m save_model_callback \u001b[38;5;241m=\u001b[39m SaveModelCallback()\n\u001b[1;32m---> 11\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtensorboard_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_model_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "tensorboard_callback = TensorBoard(log_dir=f\"playstlye_logs/{time.time()}\", histogram_freq=1)\n",
    "# Define a custom callback to save model based on validation accuracy\n",
    "class SaveModelCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        filepath = f\"./pl/{logs['val_loss']:.3f}_{logs['val_accuracy']:.3f}.h5\"\n",
    "        self.model.save(filepath)\n",
    "\n",
    "# Create an instance of the SaveModelCallback\n",
    "save_model_callback = SaveModelCallback()\n",
    "\n",
    "history = model.fit(\n",
    "    x = x_train, \n",
    "    y = y_train,\n",
    "    batch_size = 16,\n",
    "    epochs = 30,\n",
    "    validation_data=(x_val, y_val),\n",
    "    callbacks=[tensorboard_callback, save_model_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed0f073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(f\"./model_playstyle{history.history['val_accuracy'][-1]:.5f}.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58388eb",
   "metadata": {},
   "source": [
    "## ALL DONE!\n",
    "\n",
    "For using the model and creating a submission file, follow the notebook **Create Public Upload CSV.ipynb**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9436139c",
   "metadata": {},
   "source": [
    "# End of Tutorial\n",
    "\n",
    "You are free to use more modern NN architectures, a better pre-processing, feature extraction methods to achieve much better accuracy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc41e067",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
